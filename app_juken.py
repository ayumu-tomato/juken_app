import streamlit as st
import pandas as pd
import google.generativeai as genai
import datetime
import PIL.Image
import json
import re
import time
import io
import gzip
import base64

# ==========================================
# ğŸ” åˆæœŸè¨­å®š
# ==========================================
st.set_page_config(page_title="æ–°æ½Ÿé«˜æ ¡ åˆæ ¼ãƒŠãƒ“", layout="wide", page_icon="ğŸ”ï¸")

# --------------------------------------------------------------------------------
# ğŸ¨ UIãƒ‡ã‚¶ã‚¤ãƒ³ & CSS
# --------------------------------------------------------------------------------
exam_date = datetime.date(2026, 3, 4) 
today = datetime.date.today()
days_left = (exam_date - today).days
if days_left < 0: days_left = 0

st.markdown(f"""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;500;700&display=swap');
    
    html, body, [class*="css"] {{
        font-family: 'Noto Sans JP', sans-serif;
        color: #333;
    }}
    .stApp {{ background-color: #f4f7f6; }}

    /* å›ºå®šã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ */
    .fixed-countdown {{
        position: fixed;
        top: 0;
        right: 0;
        z-index: 999999;
        background: rgba(255, 255, 255, 0.95);
        border-bottom-left-radius: 15px;
        box-shadow: 0 4px 10px rgba(0,0,0,0.1);
        padding: 8px 16px;
        text-align: right;
        border-left: 5px solid #007bff;
        line-height: 1.2;
    }}
    .count-label {{ font-size: 10px; color: #666; display: block; font-weight: bold; }}
    .count-number {{ font-size: 20px; font-weight: 800; color: #d9534f; }}
    @media (max-width: 640px) {{
        .fixed-countdown {{ top: 40px; padding: 5px 10px; }}
        .count-number {{ font-size: 16px; }}
    }}

    /* QBé¢¨ã‚«ãƒ¼ãƒ‰ */
    div[data-testid="stVerticalBlock"] > div:has(div.stDataFrame), 
    div[data-testid="stVerticalBlock"] > div:has(div.stMarkdown) {{
        background-color: white;
        border-radius: 12px;
        padding: 15px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.03);
        margin-bottom: 10px;
    }}

    h1 {{
        color: #007bff;
        font-size: 1.8rem !important;
        font-weight: 800 !important;
        background: white;
        padding: 20px;
        border-radius: 12px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        margin-bottom: 20px !important;
    }}
    
    .stButton > button {{
        width: 100%;
        border-radius: 30px;
        font-weight: bold;
        padding: 0.6rem 1rem;
        border: none;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        transition: transform 0.1s;
    }}
    .stButton > button:active {{ transform: scale(0.98); }}
    button[kind="primary"] {{ background-color: #007bff !important; color: white !important; }}

    .stTabs [data-baseweb="tab-list"] {{ gap: 10px; background-color: transparent; }}
    .stTabs [data-baseweb="tab"] {{
        background-color: white;
        border-radius: 8px 8px 0 0;
        padding: 10px 20px;
        box-shadow: 0 -2px 5px rgba(0,0,0,0.02);
    }}
    .stTabs [aria-selected="true"] {{ background-color: #007bff !important; color: white !important; }}
</style>

<div class="fixed-countdown">
    <span class="count-label">æ–°æ½Ÿé«˜æ ¡å…¥è©¦ã¾ã§</span>
    <span class="count-number">ã‚ã¨ {days_left} æ—¥</span>
</div>
""", unsafe_allow_html=True)

try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    api_key = ""

if not api_key:
    st.warning("âš ï¸ Secretsã«APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

genai.configure(api_key=api_key)

# ---------------------------------------------------------
# ğŸ¤– ãƒ¢ãƒ‡ãƒ«è‡ªå‹•æ¤œå‡º
# ---------------------------------------------------------
def get_available_models():
    try:
        return [m.name.replace("models/", "") for m in genai.list_models()]
    except:
        return []

ALL_MODELS = get_available_models()

def get_best_pro_model(all_models):
    priority_list = [
        "gemini-3-pro", "gemini-3-pro-preview", "gemini-3.0-pro",
        "gemini-2.5-pro", "gemini-2.0-pro-exp",
        "gemini-1.5-pro-002", "gemini-1.5-pro-latest", "gemini-1.5-pro", "gemini-pro"
    ]
    for m in priority_list:
        if m in all_models: return m
    
    pro_models = [m for m in all_models if "pro" in m and "vision" not in m]
    if pro_models:
        pro_models.sort(reverse=True)
        return pro_models[0]
            
    return "gemini-1.5-flash"

def get_best_flash_model(all_models):
    priority_list = [
        "gemini-2.5-flash", "gemini-2.5-flash-001", "gemini-2.0-flash", "gemini-2.0-flash-exp",
        "gemini-1.5-flash-002", "gemini-1.5-flash-latest", "gemini-1.5-flash", "gemini-1.5-flash-8b"
    ]
    for m in priority_list:
        if m in all_models: return m
    return get_best_pro_model(all_models)

MODEL_NAME_PRO = get_best_pro_model(ALL_MODELS)
MODEL_NAME_FLASH = get_best_flash_model(ALL_MODELS)

try:
    model_pro = genai.GenerativeModel(MODEL_NAME_PRO)
    model_flash = genai.GenerativeModel(MODEL_NAME_FLASH)
    model_vision = genai.GenerativeModel(MODEL_NAME_PRO)
    st.sidebar.success(f"ğŸš€ Engine: {MODEL_NAME_PRO}")
except Exception as e:
    st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# ---------------------------------------------------------
# ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç† (ä¿å­˜ãƒ­ã‚¸ãƒƒã‚¯ä¿®æ­£ç‰ˆ)
# ---------------------------------------------------------
if 'data_store' not in st.session_state: st.session_state['data_store'] = {}
if 'clean_df' not in st.session_state: st.session_state['clean_df'] = pd.DataFrame()
if 'category_map' not in st.session_state: st.session_state['category_map'] = {}
if 'textbooks' not in st.session_state: st.session_state['textbooks'] = {}

def compress_data_to_code(data_dict):
    """ãƒ‡ãƒ¼ã‚¿ã‚’åœ§ç¸®ã—ã¦æ–‡å­—åˆ—åŒ–ã™ã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰"""
    try:
        # default=str ã‚’è¿½åŠ ã—ã¦ã€æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚„Numpyå‹ãŒã‚ã£ã¦ã‚‚å¼·åˆ¶çš„ã«æ–‡å­—åˆ—åŒ–ã™ã‚‹
        json_str = json.dumps(data_dict, ensure_ascii=False, default=str)
        compressed = gzip.compress(json_str.encode('utf-8'))
        b64_str = base64.b64encode(compressed).decode('utf-8')
        return b64_str
    except Exception as e:
        st.error(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚³ãƒ¼ãƒ‰ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def decompress_code_to_data(b64_str):
    """æ–‡å­—åˆ—ã‚’ãƒ‡ãƒ¼ã‚¿ã«æˆ»ã™"""
    try:
        compressed = base64.b64decode(b64_str)
        json_str = gzip.decompress(compressed).decode('utf-8')
        return json.loads(json_str)
    except Exception as e:
        st.error(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿å¾©å…ƒä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

FIXED_CATEGORIES = {
    "å›½èª": ["æ¼¢å­—", "æ–‡æ³•", "è©•è«–", "å¤æ–‡", "ãã®ä»–"],
    "æ•°å­¦": ["æ­£è² ã®æ•°ãƒ»æ–‡å­—ã¨å¼", "ä¸€æ¬¡æ–¹ç¨‹å¼ãƒ»é€£ç«‹æ–¹ç¨‹å¼", "å¹³æ–¹æ ¹", "å¼ã®å±•é–‹ã¨å› æ•°åˆ†è§£", "äºŒæ¬¡æ–¹ç¨‹å¼", "æ¯”ä¾‹ãƒ»åæ¯”ä¾‹", "ä¸€æ¬¡é–¢æ•°", "é–¢æ•°y=ax^2", "å¹³é¢å›³å½¢ï¼ˆä½œå›³ãƒ»ç§»å‹•ãƒ»ãŠã†ãå½¢ï¼‰", "ç©ºé–“å›³å½¢", "å›³å½¢ã®æ€§è³ªã¨è¨¼æ˜ï¼ˆåˆåŒãƒ»ç›¸ä¼¼ãƒ»å††ï¼‰", "ç¢ºç‡ãƒ»çµ±è¨ˆï¼ˆãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨ãƒ»ä¸‰å¹³æ–¹ã®å®šç†ï¼‰", "èåˆå•é¡Œ", "ãã®ä»–"],
    "è‹±èª": ["ãƒªã‚¹ãƒ‹ãƒ³ã‚°", "å’Œè¨³", "è‹±è¨³", "è‹±ä½œæ–‡", "æ–‡æ³•", "èª­è§£", "èåˆå•é¡Œ", "ãã®ä»–"],
    "ç†ç§‘": ["ã€ç‰©ç†ã€‘å…‰ãƒ»éŸ³ãƒ»åŠ›", "ã€ç‰©ç†ã€‘é›»æµã¨ç£ç•Œ", "ã€ç‰©ç†ã€‘é‹å‹•ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼", "ã€åŒ–å­¦ã€‘èº«ã®å›ã‚Šã®ç‰©è³ªãƒ»æ°—ä½“ãƒ»æ°´æº¶æ¶²", "ã€åŒ–å­¦ã€‘åŒ–å­¦å¤‰åŒ–ã¨åŸå­ãƒ»åˆ†å­", "ã€åŒ–å­¦ã€‘åŒ–å­¦å¤‰åŒ–ã¨ã‚¤ã‚ªãƒ³ãƒ»é›»æ± ", "ã€ç”Ÿç‰©ã€‘æ¤ç‰©ã®ç”Ÿæ´»ã¨ç¨®é¡", "ã€ç”Ÿç‰©ã€‘å‹•ç‰©ã®ç”Ÿæ´»ã¨ç”Ÿç‰©ã®å¤‰é·", "ã€ç”Ÿç‰©ã€‘ç”Ÿå‘½ã®é€£ç¶šæ€§ï¼ˆéºä¼ãƒ»ç´°èƒï¼‰", "ã€åœ°å­¦ã€‘å¤§åœ°ã®å¤‰åŒ–ï¼ˆç«å±±ãƒ»åœ°éœ‡ãƒ»åœ°å±¤ï¼‰", "ã€åœ°å­¦ã€‘æ°—è±¡ã¨ãã®å¤‰åŒ–", "ã€åœ°å­¦ã€‘åœ°çƒã¨å®‡å®™", "èåˆå•é¡Œ", "ãã®ä»–"],
    "ç¤¾ä¼š": ["ã€åœ°ç†ã€‘ä¸–ç•Œã®å§¿ãƒ»æ°—å€™ãƒ»ç”Ÿæ´»æ–‡åŒ–", "ã€åœ°ç†ã€‘ä¸–ç•Œã®è«¸åœ°åŸŸ", "ã€åœ°ç†ã€‘æ—¥æœ¬ã®å§¿ãƒ»ç”£æ¥­ãƒ»è³‡æºã‚¨ãƒãƒ«ã‚®ãƒ¼", "ã€åœ°ç†ã€‘æ—¥æœ¬ã®è«¸åœ°åŸŸ", "ã€æ­´å²ã€‘å¤ä»£ã€œä¸­ä¸–ï¼ˆæ–‡æ˜ã€œå®¤ç”ºï¼‰", "ã€æ­´å²ã€‘è¿‘ä¸–ï¼ˆå®‰åœŸæ¡ƒå±±ãƒ»æ±Ÿæˆ¸ï¼‰", "ã€æ­´å²ã€‘è¿‘ä»£â‘ ï¼ˆæ˜æ²»ã€œç¬¬ä¸€æ¬¡å¤§æˆ¦ï¼‰", "ã€æ­´å²ã€‘è¿‘ä»£â‘¡ã€œç¾ä»£ï¼ˆæ˜­å’Œã€œç¾åœ¨ï¼‰", "ã€å…¬æ°‘ã€‘ç¾ä»£ç¤¾ä¼šãƒ»æ—¥æœ¬å›½æ†²æ³•ãƒ»äººæ¨©", "ã€å…¬æ°‘ã€‘æ”¿æ²»ã®ä»•çµ„ã¿", "ã€å…¬æ°‘ã€‘çµŒæ¸ˆã®ä»•çµ„ã¿", "ã€å…¬æ°‘ã€‘å›½éš›ç¤¾ä¼šãƒ»ç’°å¢ƒå•é¡Œ", "èåˆå•é¡Œ", "ãã®ä»–"]
}

# ---------------------------------------------------------
# ğŸ› ï¸ é–¢æ•°å®šç¾©
# ---------------------------------------------------------
def ask_gemini_robust(prompt, image_list=None, use_flash=False):
    max_retries = 3
    if image_list: target_model = model_vision
    elif use_flash: target_model = model_flash
    else: target_model = model_pro

    for attempt in range(max_retries):
        try:
            if image_list: response = target_model.generate_content([prompt] + image_list)
            else: response = target_model.generate_content(prompt)
            return response.text
        except Exception as e:
            if "429" in str(e) or "Quota" in str(e):
                st.toast(f"â³ å¾…æ©Ÿä¸­ ({attempt+1}/3)")
                time.sleep((attempt + 1) * 3)
            else: return f"ã‚¨ãƒ©ãƒ¼: {e}"
    return "âŒ å¿œç­”ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

def detect_subject(file_name):
    name_str = str(file_name)
    for sub in ['æ•°å­¦', 'è‹±èª', 'ç†ç§‘', 'ç¤¾ä¼š', 'å›½èª']:
        if sub in name_str: return sub
    return 'ãã®ä»–'

def parse_csv(file):
    try:
        file.seek(0)
        try: df = pd.read_csv(file, header=None)
        except: 
            file.seek(0)
            df = pd.read_csv(file, header=None, encoding='cp932')
        
        header_row_mask = df.apply(lambda r: r.astype(str).str.contains('å¤§å•|å†…å®¹').any(), axis=1)
        if len(df[header_row_mask]) > 0:
            idx = df[header_row_mask].index[0]
            col_idx = 0
            for c in df.columns:
                val = str(df.iloc[idx][c])
                if 'å¤§å•' in val or 'å†…å®¹' in val:
                    col_idx = c
                    break
            
            subset = df.iloc[idx:, col_idx:].reset_index(drop=True).T
            
            raw_cols = [str(val).strip() for val in subset.iloc[0]]
            new_cols = []
            seen = {}
            for c in raw_cols:
                if c in seen:
                    seen[c] += 1
                    new_cols.append(f"{c}_{seen[c]}")
                else:
                    seen[c] = 0
                    new_cols.append(c)
            subset.columns = new_cols
            
            subset = subset[1:]
            
            if 'å¤§å•' in subset.columns: subset = subset.dropna(subset=['å¤§å•'])
            subset['ç‚¹æ•°'] = pd.to_numeric(subset['ç‚¹æ•°'], errors='coerce').fillna(0)
            subset['é…ç‚¹'] = pd.to_numeric(subset['é…ç‚¹'], errors='coerce').fillna(0)
            subset['ãƒ•ã‚¡ã‚¤ãƒ«å'] = str(file.name)
            subset['æ•™ç§‘'] = detect_subject(file.name)
            
            if 'ç‚¹æ•°' in subset.columns: return subset
    except: pass
    return None

def process_and_categorize():
    if not st.session_state['data_store']:
        st.session_state['clean_df'] = pd.DataFrame()
        return

    model_label = MODEL_NAME_PRO 
    
    with st.status(f"ğŸš€ ãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­... (Engine: {model_label})", expanded=True) as status:
        st.write("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆä¸­...")
        try:
            raw_df = pd.concat(st.session_state['data_store'].values(), ignore_index=True)
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿çµåˆã‚¨ãƒ©ãƒ¼: {e}")
            st.warning("ä¸€éƒ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒä¸æ­£ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã€Œå…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã€ã—ã¦ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚")
            status.update(label="âš ï¸ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ", state="error")
            return

        time.sleep(0.1)
        
        st.write("ğŸ” æœªçŸ¥ã®å˜å…ƒã‚’æ¤œç´¢ä¸­...")
        unique_pairs = raw_df[['æ•™ç§‘', 'å†…å®¹']].drop_duplicates()
        unknown_list = []
        for _, row in unique_pairs.iterrows():
            subj = row['æ•™ç§‘']
            topic = str(row['å†…å®¹']).strip()
            is_perfect = False
            if subj in FIXED_CATEGORIES and topic in FIXED_CATEGORIES[subj]: is_perfect = True
            
            if not is_perfect and (subj, topic) not in st.session_state['category_map']:
                unknown_list.append(f"{subj}: {topic}")
        
        if unknown_list:
            st.write(f"ğŸ§  {len(unknown_list)} ä»¶ã®å˜å…ƒã‚’AIãŒæ€è€ƒãƒ»åˆ†é¡ä¸­...")
            categories_str = json.dumps(FIXED_CATEGORIES, ensure_ascii=False, indent=2)
            prompt = f"""
            å…¥è©¦ãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚
            å…¥åŠ›ã•ã‚ŒãŸã€Œæ•™ç§‘: å…ƒã®å˜å…ƒåã€ã‚’åˆ†æã—ã€ä»¥ä¸‹ã®ã€å®šç¾©æ¸ˆã¿ãƒã‚¹ã‚¿ã€‘ã®ä¸­ã§æœ€ã‚‚é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚
            ã€å®šç¾©æ¸ˆã¿ãƒã‚¹ã‚¿ã€‘
            {categories_str}
            ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‘
            """ + "\n".join(unknown_list) + """
            ã€å‡ºåŠ›å½¢å¼ã€‘
            JSONå½¢å¼ã®è¾æ›¸ `{ "æ•™ç§‘: å…ƒã®å˜å…ƒå": "å®šç¾©æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªå", ... }` ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            """
            response = ask_gemini_robust(prompt, use_flash=False)
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    mapping = json.loads(json_match.group())
                    for k, v in mapping.items():
                        if ':' in k:
                            s, t = k.split(':', 1)
                            st.session_state['category_map'][(s.strip(), t.strip())] = v.strip()
            except: st.warning("ä¸€éƒ¨ã®åˆ†é¡ã«å¤±æ•—")

        st.write("ğŸ’¾ ä¿å­˜ä¸­...")
        df_clean = raw_df.copy()
        if 'è©³ç´°' not in df_clean.columns: df_clean['è©³ç´°'] = df_clean['å†…å®¹']
        def apply_mapping(row):
            key = (row['æ•™ç§‘'], str(row['å†…å®¹']).strip())
            mapped = st.session_state['category_map'].get(key, row['å†…å®¹'])
            return mapped if mapped else row['å†…å®¹']

        df_clean['å†…å®¹'] = df_clean.apply(apply_mapping, axis=1)
        st.session_state['clean_df'] = df_clean
        status.update(label="âœ… å®Œäº†ï¼", state="complete", expanded=False)

def get_status_emoji(rate):
    if rate <= 50: return "ğŸ”´"
    elif rate <= 70: return "ğŸŸ¡"
    else: return "ğŸŸ¢"

# ---------------------------------------------------------
# ğŸ–¥ï¸ ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š (ä¿®æ­£: å®‰å…¨ãªä¿å­˜ãƒ»å¾©å…ƒ)
# ---------------------------------------------------------
with st.sidebar:
    st.subheader("ğŸ“² ç°¡å˜ãƒ‡ãƒ¼ã‚¿ç§»è¡Œ")
    st.caption("åˆ¥ã®ãƒ‡ãƒã‚¤ã‚¹ã«ç§»ã‚‹æ™‚ã¯ã€Œã‚»ãƒ¼ãƒ–ã‚³ãƒ¼ãƒ‰ã€ã‚’ä½¿ã†ã¨ä¾¿åˆ©ã§ã™ã€‚")
    
    sync_tab1, sync_tab2 = st.tabs(["ğŸ“¤ ä¿å­˜(ã‚³ãƒ”ãƒ¼)", "ğŸ“¥ å¾©å…ƒ(è²¼ä»˜)"])
    
    with sync_tab1:
        if st.session_state['data_store'] or st.session_state['textbooks']:
            
            # --- ã€ä¿®æ­£ã€‘Category Mapã®ã‚­ãƒ¼(ã‚¿ãƒ—ãƒ«)ã‚’æ–‡å­—åˆ—ã«å®‰å…¨å¤‰æ› ---
            safe_category_map = {}
            for k, v in st.session_state['category_map'].items():
                try:
                    if isinstance(k, (list, tuple)) and len(k) >= 2:
                        safe_category_map[f"{k[0]}:{k[1]}"] = v
                    else:
                        safe_category_map[str(k)] = v
                except: continue

            # --- ã€ä¿®æ­£ã€‘DataFrameã‚’JSONåŒ– (æ—¥ä»˜ç­‰ã«å¯¾å¿œ) ---
            safe_data_store = {}
            for name, df in st.session_state['data_store'].items():
                try:
                    safe_data_store[name] = df.to_json(orient='split', force_ascii=False, date_format='iso')
                except:
                    pass

            backup_data = {
                'textbooks': st.session_state['textbooks'],
                'data_store': safe_data_store,
                'category_map': safe_category_map
            }
            
            save_code = compress_data_to_code(backup_data)
            
            if save_code:
                st.info("ğŸ‘‡ ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã€LINEã‚„ãƒ¡ãƒ¢å¸³ã§ã‚¹ãƒãƒ›ã«é€ã£ã¦ãã ã•ã„ã€‚")
                st.code(save_code, language="text")
            else:
                st.warning("ä¿å­˜ã‚³ãƒ¼ãƒ‰ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ï¼ˆã‚¨ãƒ©ãƒ¼è©³ç´°ã¯ç”»é¢ä¸Šéƒ¨ï¼‰")
        else:
            st.caption("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    with sync_tab2:
        input_code = st.text_area("ã“ã“ã«ã‚»ãƒ¼ãƒ–ã‚³ãƒ¼ãƒ‰ã‚’è²¼ã‚Šä»˜ã‘:", height=100)
        if st.button("å¾©å…ƒã‚’å®Ÿè¡Œ"):
            if input_code:
                restored_data = decompress_code_to_data(input_code.strip())
                if restored_data:
                    try:
                        # æ•™æãƒ‡ãƒ¼ã‚¿ã®å¾©å…ƒ
                        if 'textbooks' in restored_data: st.session_state['textbooks'] = restored_data['textbooks']
                        
                        # æˆç¸¾ãƒ‡ãƒ¼ã‚¿ã®å¾©å…ƒ
                        if 'data_store' in restored_data:
                            st.session_state['data_store'] = {}
                            for name, df_json in restored_data['data_store'].items():
                                st.session_state['data_store'][name] = pd.read_json(df_json, orient='split')
                        
                        # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ—ã®å¾©å…ƒï¼ˆæ–‡å­—åˆ— "æ•°:é–¢" â†’ ã‚¿ãƒ—ãƒ« ("æ•°","é–¢") ã«æˆ»ã™ï¼‰
                        if 'category_map' in restored_data:
                            st.session_state['category_map'] = {}
                            for k, v in restored_data['category_map'].items():
                                if ':' in k:
                                    s, t = k.split(':', 1)
                                    st.session_state['category_map'][(s, t)] = v
                                else:
                                    # ä¸‡ãŒä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒé•ã†å ´åˆ
                                    st.session_state['category_map'][(k, k)] = v
                        
                        st.session_state['clean_df'] = pd.DataFrame() 
                        st.success("âœ… å¾©å…ƒå®Œäº†ï¼ç”»é¢ã‚’æ›´æ–°ã—ã¾ã™ã€‚")
                        time.sleep(1)
                        st.rerun()
                    except Exception as e:
                        st.error(f"å¾©å…ƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.error("ã‚³ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã‚‹ã‹ã€å£Šã‚Œã¦ã„ã¾ã™ã€‚")

    st.markdown("---")
    st.subheader("ğŸ“š ç™»éŒ²æ¸ˆã¿å‚è€ƒæ›¸")
    if st.session_state['textbooks']:
        for subj, book in list(st.session_state['textbooks'].items()):
            if book:
                c1, c2 = st.columns([0.8, 0.2])
                c1.write(f"**{subj}**: {book}")
                if c2.button("ğŸ—‘ï¸", key=f"del_book_{subj}"):
                    del st.session_state['textbooks'][subj]
                    st.rerun()
    
    with st.expander("è¿½åŠ ãƒ»ç·¨é›†"):
        with st.form("textbook_form"):
            tb_math = st.text_input("æ•°å­¦", value=st.session_state['textbooks'].get('æ•°å­¦', ''))
            tb_eng = st.text_input("è‹±èª", value=st.session_state['textbooks'].get('è‹±èª', ''))
            tb_sci = st.text_input("ç†ç§‘", value=st.session_state['textbooks'].get('ç†ç§‘', ''))
            tb_soc = st.text_input("ç¤¾ä¼š", value=st.session_state['textbooks'].get('ç¤¾ä¼š', ''))
            tb_jpn = st.text_input("å›½èª", value=st.session_state['textbooks'].get('å›½èª', ''))
            if st.form_submit_button("ä¿å­˜"):
                st.session_state['textbooks'] = {'æ•°å­¦': tb_math, 'è‹±èª': tb_eng, 'ç†ç§‘': tb_sci, 'ç¤¾ä¼š': tb_soc, 'å›½èª': tb_jpn}
                st.rerun()

    st.markdown("---")
    st.subheader("ğŸ’¾ ç™»éŒ²æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«")
    if st.session_state['data_store']:
        for file_name in list(st.session_state['data_store'].keys()):
            c1, c2 = st.columns([0.85, 0.15])
            c1.text(file_name)
            if c2.button("ğŸ—‘ï¸", key=f"del_file_{file_name}"):
                del st.session_state['data_store'][file_name]
                st.session_state['clean_df'] = pd.DataFrame()
                st.rerun()
        
        if st.button("ğŸš¨ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤", type="primary"):
            st.session_state['data_store'] = {}
            st.session_state['clean_df'] = pd.DataFrame()
            st.session_state['category_map'] = {}
            st.rerun()
    else:
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")

# ---------------------------------------------------------
# ğŸ“‚ ãƒ¡ã‚¤ãƒ³ç”»é¢
# ---------------------------------------------------------
st.markdown("### 1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & è§£æ")
col_up, col_btn = st.columns([3, 1])

with col_up:
    uploaded_files = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«", accept_multiple_files=True, type=['csv'], label_visibility="collapsed")

with col_btn:
    if st.button("ğŸš€ AIè§£æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        if uploaded_files:
            new_count = 0
            for file in uploaded_files:
                df = parse_csv(file)
                if df is not None:
                    st.session_state['data_store'][file.name] = df
                    new_count += 1
            if new_count > 0:
                process_and_categorize()
            else:
                st.warning("æœ‰åŠ¹ãªCSVãŒã‚ã‚Šã¾ã›ã‚“")
        elif st.session_state['data_store']:
            process_and_categorize()
        else:
            st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")

if not st.session_state['clean_df'].empty:
    df_show = st.session_state['clean_df']
    st.markdown("---")
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š å…¨ä½“åˆ†æ", "ğŸ“– å¾©ç¿’ï¼†ãƒ†ã‚¹ãƒˆ", "ğŸ“… åˆæ ¼è¨ˆç”»", "ğŸ“· ç”»åƒæ¡ç‚¹"])

    with tab1:
        # ãƒ‡ãƒ¼ã‚¿é›†è¨ˆ
        summary = df_show.groupby(['æ•™ç§‘', 'å†…å®¹'])[['ç‚¹æ•°', 'é…ç‚¹']].sum().reset_index()
        summary['å¾—ç‚¹ç‡(%)'] = (summary['ç‚¹æ•°'] / summary['é…ç‚¹'] * 100).fillna(0).round(1)
        
        # åˆ¤å®šã‚«ãƒ©ãƒ ã®è¿½åŠ  (ğŸ”´/ğŸŸ¡/ğŸŸ¢)
        summary['åˆ¤å®š'] = summary['å¾—ç‚¹ç‡(%)'].apply(get_status_emoji)
        
        # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†
        summary_clean = summary[['æ•™ç§‘', 'å†…å®¹', 'åˆ¤å®š', 'å¾—ç‚¹ç‡(%)']].copy()

        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader("âš ï¸ å…¨ä½“ï¼šå„ªå…ˆå¾©ç¿’å˜å…ƒ")
            st.dataframe(
                summary_clean.sort_values('å¾—ç‚¹ç‡(%)').head(10), 
                column_config={
                    "å¾—ç‚¹ç‡(%)": st.column_config.ProgressColumn(
                        "å¾—ç‚¹ç‡", 
                        format="%.1f%%", 
                        min_value=0, 
                        max_value=100
                    ),
                    "åˆ¤å®š": st.column_config.TextColumn("çŠ¶æ…‹", width="small")
                },
                use_container_width=True, 
                hide_index=True
            )
        with col2:
            st.subheader("æ•™ç§‘åˆ¥å¹³å‡")
            sub_sum = df_show.groupby('æ•™ç§‘')[['ç‚¹æ•°', 'é…ç‚¹']].sum().reset_index()
            sub_sum['å¾—ç‚¹ç‡(%)'] = (sub_sum['ç‚¹æ•°']/sub_sum['é…ç‚¹']*100).fillna(0).round(1)
            st.dataframe(
                sub_sum[['æ•™ç§‘', 'å¾—ç‚¹ç‡(%)']], 
                column_config={
                    "å¾—ç‚¹ç‡(%)": st.column_config.ProgressColumn(
                        "å¹³å‡ç‚¹ç‡",
                        format="%.1f%%",
                        min_value=0,
                        max_value=100
                    )
                },
                hide_index=True
            )
            
        st.markdown("---")
        st.subheader("ğŸ“š æ•™ç§‘ã”ã¨ã®å¼±ç‚¹")
        subjects = df_show['æ•™ç§‘'].unique()
        cols = st.columns(len(subjects)) if len(subjects) > 0 else [st.container()]
        
        for i, sub in enumerate(subjects):
            with cols[i]:
                st.markdown(f"**{sub}**")
                sub_df = summary_clean[summary_clean['æ•™ç§‘'] == sub].sort_values('å¾—ç‚¹ç‡(%)').head(5)
                if not sub_df.empty:
                    st.dataframe(
                        sub_df[['å†…å®¹', 'åˆ¤å®š', 'å¾—ç‚¹ç‡(%)']], 
                        column_config={
                            "å¾—ç‚¹ç‡(%)": st.column_config.ProgressColumn(
                                format="%.0f%%", min_value=0, max_value=100
                            ),
                            "åˆ¤å®š": st.column_config.TextColumn(width="small")
                        },
                        use_container_width=True, 
                        hide_index=True
                    )
                else: st.caption("ãƒ‡ãƒ¼ã‚¿ãªã—")

    with tab2:
        st.subheader("AIå®¶åº­æ•™å¸«ã«ã‚ˆã‚‹æŒ‡å°")
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        summary_t2 = df_show.groupby(['æ•™ç§‘', 'å†…å®¹'])[['ç‚¹æ•°', 'é…ç‚¹']].sum().reset_index()
        summary_t2['å¾—ç‚¹ç‡(%)'] = (summary_t2['ç‚¹æ•°'] / summary_t2['é…ç‚¹'] * 100).fillna(0).round(1)

        c1, c2 = st.columns(2)
        with c1: 
            sel_sub = st.selectbox("æ•™ç§‘", summary_t2['æ•™ç§‘'].unique())
        
        with c2:
            sub_topics = summary_t2[summary_t2['æ•™ç§‘']==sel_sub].sort_values('å¾—ç‚¹ç‡(%)')
            
            topic_map = {}
            for _, row in sub_topics.iterrows():
                icon = get_status_emoji(row['å¾—ç‚¹ç‡(%)'])
                display_name = f"{icon} {row['å†…å®¹']} ({row['å¾—ç‚¹ç‡(%)']}%)"
                topic_map[display_name] = row['å†…å®¹']
            
            sel_top_display = st.selectbox("å˜å…ƒ (ğŸ”´è‹¦æ‰‹ / ğŸŸ¡æ³¨æ„ / ğŸŸ¢å®šç€)", options=list(topic_map.keys()))
            sel_top = topic_map[sel_top_display]
        
        target_rows = df_show[(df_show['æ•™ç§‘']==sel_sub) & (df_show['å†…å®¹']==sel_top)]
        rate = (target_rows['ç‚¹æ•°'].sum() / target_rows['é…ç‚¹'].sum() * 100).round(1)
        original_topics = target_rows['è©³ç´°'].unique().tolist()
        original_topics_str = "ã€".join([str(t) for t in original_topics])
        
        st.info(f"é¸æŠå˜å…ƒ: **{sel_top}** (å¾—ç‚¹ç‡: {rate}%)")
        st.caption(f"è©³ç´°: {original_topics_str}")
        book = st.session_state['textbooks'].get(sel_sub, "å‚è€ƒæ›¸")
        
        if st.button("â‘  å¾©ç¿’ãƒã‚¤ãƒ³ãƒˆã‚’èã"):
            with st.status(f"ğŸ¤– AI({MODEL_NAME_PRO})ãŒæ€è€ƒä¸­...", expanded=True) as status:
                st.write("1. åˆ†æä¸­...")
                p = f"æ–°æ½Ÿé«˜æ ¡å¿—æœ›ã€‚æ•™ç§‘: {sel_sub}, è‹¦æ‰‹ã‚«ãƒ†ã‚´ãƒª: {sel_top}ï¼ˆè©³ç´°: {original_topics_str}ï¼‰, å¾—ç‚¹ç‡: {rate}%, å‚è€ƒæ›¸: {book}ã€‚å¾©ç¿’ãƒã‚¤ãƒ³ãƒˆã¨ãƒã‚§ãƒƒã‚¯é …ç›®3ã¤ã‚’æ•™ãˆã¦ã€‚"
                res = ask_gemini_robust(p, use_flash=False)
                st.session_state['guide'] = res
                status.update(label="âœ… å®Œäº†ï¼", state="complete", expanded=False)
        
        if 'guide' in st.session_state:
            st.markdown(st.session_state['guide'])
            if st.button("â‘¡ ç¢ºèªãƒ†ã‚¹ãƒˆã‚’ä½œæˆ"):
                with st.status("ğŸ“ å•é¡Œä½œæˆä¸­...", expanded=True) as status:
                    p2 = f"æ–°æ½Ÿé«˜æ ¡å…¥è©¦ãƒ¬ãƒ™ãƒ«ã€‚{sel_sub}ã®ã€Œ{sel_top}ã€ï¼ˆè©³ç´°: {original_topics_str}ï¼‰ã®å®Ÿè·µå•é¡Œ1å•ã€‚è§£ç­”è§£èª¬ä»˜ãã€‚"
                    res = ask_gemini_robust(p2, use_flash=False)
                    st.session_state['test'] = res
                    status.update(label="âœ… å®Œäº†ï¼", state="complete", expanded=False)
        
        if 'test' in st.session_state:
            st.markdown("---")
            st.markdown(st.session_state['test'])

    with tab3:
        if st.button("åˆæ ¼ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ"):
            with st.status("ğŸ“… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç«‹æ¡ˆä¸­...", expanded=True) as status:
                st.write("1. å¼±ç‚¹ã‚’æŠ½å‡ºä¸­...")
                summary = df_show.groupby(['æ•™ç§‘', 'å†…å®¹'])[['ç‚¹æ•°', 'é…ç‚¹']].sum().reset_index()
                summary['å¾—ç‚¹ç‡'] = (summary['ç‚¹æ•°'] / summary['é…ç‚¹'] * 100)
                weak_points = summary.sort_values('å¾—ç‚¹ç‡').head(5)
                weak_str = ""
                for _, row in weak_points.iterrows():
                    weak_str += f"- {row['æ•™ç§‘']}: {row['å†…å®¹']} (å¾—ç‚¹ç‡{row['å¾—ç‚¹ç‡']:.1f}%)\n"
                
                st.write("2. ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ æ§‹ç¯‰ä¸­...")
                prompt = f"""
                ä»Šæ—¥({datetime.date.today()})ã‹ã‚‰å…¥è©¦({datetime.date(2026, 3, 4)})ã¾ã§ã®æ–°æ½Ÿé«˜æ ¡åˆæ ¼ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
                ã€ç‰¹ã«è‹¦æ‰‹ãªåˆ†é‡ã€‘
                {weak_str}
                å…·ä½“çš„ãªå¯¾ç­–ã‚’å«ã‚ã¦ä½œæˆã—ã¦ãã ã•ã„ã€‚
                """
                res = ask_gemini_robust(prompt, use_flash=False)
                st.markdown(res)
                status.update(label="âœ… å®Œæˆï¼", state="complete", expanded=False)

    with tab4:
        st.subheader("ğŸ“· ç”»åƒæ¡ç‚¹ï¼†æŒ‡å°")
        col_img1, col_img2, col_img3 = st.columns(3)
        with col_img1: img_prob = st.file_uploader("â‘  å•é¡Œç”»åƒ", type=['png', 'jpg', 'jpeg'])
        with col_img2: img_user = st.file_uploader("â‘¡ è§£ç­”ç”»åƒ", type=['png', 'jpg', 'jpeg'])
        with col_img3: img_ans = st.file_uploader("â‘¢ æ¨¡ç¯„è§£ç­”ç”»åƒ", type=['png', 'jpg', 'jpeg'])
        
        if img_prob and img_user and img_ans:
            if st.button(f"ğŸš€ æ¡ç‚¹å®Ÿè¡Œ ({MODEL_NAME_PRO})"):
                with st.status("ğŸ‘€ è§£æä¸­...", expanded=True) as status:
                    images = [PIL.Image.open(img_prob), PIL.Image.open(img_user), PIL.Image.open(img_ans)]
                    prompt_v = "æ–°æ½Ÿé«˜æ ¡å¿—æœ›ã€‚3æšã®ç”»åƒã‹ã‚‰ã€å³å¯†ãªæ¡ç‚¹ã€æ·»å‰Šã€å¼±ç‚¹åˆ†æã€é¡é¡Œã®æç¤ºã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
                    res = ask_gemini_robust(prompt_v, images)
                    st.markdown(res)
                    status.update(label="âœ… å®Œäº†ï¼", state="complete", expanded=False)
else:
    st.info("ğŸ‘† ä¸Šè¨˜ã‹ã‚‰CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã€ŒAIè§£æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
