import streamlit as st
import pandas as pd
import google.generativeai as genai
import datetime
import PIL.Image
import json
import re
import time
import io

# ==========================================
# ğŸ” åˆæœŸè¨­å®š
# ==========================================
st.set_page_config(page_title="æ–°æ½Ÿé«˜æ ¡ åˆæ ¼ãƒŠãƒ“", layout="wide")
st.title("ğŸ”ï¸ æ–°æ½Ÿé«˜æ ¡ åˆæ ¼ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ & å¾¹åº•å¾©ç¿’")

try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    api_key = ""

if not api_key:
    st.warning("âš ï¸ Secretsã«APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

genai.configure(api_key=api_key)

# ---------------------------------------------------------
# ğŸ¤– ãƒ¢ãƒ‡ãƒ«è‡ªå‹•æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ§‹æˆ)
# ---------------------------------------------------------
def get_available_models():
    try:
        return [m.name.replace("models/", "") for m in genai.list_models()]
    except:
        return []

ALL_MODELS = get_available_models()

def get_best_pro_model(all_models):
    """æŒ‡å°ãƒ»æ¡ç‚¹ç”¨ï¼šæœ€æ–°ã®Proãƒ¢ãƒ‡ãƒ«ã‚’æ¢ã™"""
    priority_list = [
        "gemini-3-pro",
        "gemini-3-pro-preview",
        "gemini-3.0-pro",
        "gemini-2.5-pro",
        "gemini-2.0-pro-exp",
        "gemini-1.5-pro-002",
        "gemini-1.5-pro-latest",
        "gemini-1.5-pro",
        "gemini-pro"
    ]
    for m in priority_list:
        if m in all_models: return m
    
    # ãƒªã‚¹ãƒˆã«ãªãã¦ã‚‚ProãŒã‚ã‚Œã°ä½¿ã†
    pro_models = [m for m in all_models if "pro" in m and "vision" not in m]
    if pro_models:
        pro_models.sort(reverse=True)
        return pro_models[0]
            
    return "gemini-1.5-flash"

def get_best_flash_model(all_models):
    """å˜å…ƒæ•´ç†ç”¨ï¼šæœ€æ–°ã®Flashãƒ¢ãƒ‡ãƒ«ã‚’æ¢ã™"""
    priority_list = [
        "gemini-2.5-flash",
        "gemini-2.5-flash-001",
        "gemini-2.0-flash",
        "gemini-2.0-flash-exp",
        "gemini-1.5-flash-002",
        "gemini-1.5-flash-latest",
        "gemini-1.5-flash",
        "gemini-1.5-flash-8b"
    ]
    for m in priority_list:
        if m in all_models: return m
    
    return get_best_pro_model(all_models)

MODEL_NAME_PRO = get_best_pro_model(ALL_MODELS)
MODEL_NAME_FLASH = get_best_flash_model(ALL_MODELS)

try:
    model_pro = genai.GenerativeModel(MODEL_NAME_PRO)
    model_flash = genai.GenerativeModel(MODEL_NAME_FLASH)
    model_vision = genai.GenerativeModel(MODEL_NAME_PRO)
    
    st.sidebar.success(f"ğŸš€ Guidance: {MODEL_NAME_PRO}")
    st.sidebar.info(f"âš¡ Categorize: {MODEL_NAME_FLASH}")
except Exception as e:
    st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop()


# ---------------------------------------------------------
# ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†
# ---------------------------------------------------------
if 'data_store' not in st.session_state: st.session_state['data_store'] = {}
if 'clean_df' not in st.session_state: st.session_state['clean_df'] = pd.DataFrame()
if 'category_map' not in st.session_state: st.session_state['category_map'] = {}
if 'textbooks' not in st.session_state: st.session_state['textbooks'] = {}

# å®šç¾©æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒª
FIXED_CATEGORIES = {
    "å›½èª": [
        "æ¼¢å­—", "æ–‡æ³•", "è©•è«–", "å¤æ–‡", "ãã®ä»–"
    ],
    "æ•°å­¦": [
        "æ­£è² ã®æ•°ãƒ»æ–‡å­—ã¨å¼", "ä¸€æ¬¡æ–¹ç¨‹å¼ãƒ»é€£ç«‹æ–¹ç¨‹å¼", "å¹³æ–¹æ ¹", "å¼ã®å±•é–‹ã¨å› æ•°åˆ†è§£", 
        "äºŒæ¬¡æ–¹ç¨‹å¼", "æ¯”ä¾‹ãƒ»åæ¯”ä¾‹", "ä¸€æ¬¡é–¢æ•°", "é–¢æ•°y=ax^2", 
        "å¹³é¢å›³å½¢ï¼ˆä½œå›³ãƒ»ç§»å‹•ãƒ»ãŠã†ãå½¢ï¼‰", "ç©ºé–“å›³å½¢", "å›³å½¢ã®æ€§è³ªã¨è¨¼æ˜ï¼ˆåˆåŒãƒ»ç›¸ä¼¼ãƒ»å††ï¼‰", 
        "ç¢ºç‡ãƒ»çµ±è¨ˆï¼ˆãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨ãƒ»ä¸‰å¹³æ–¹ã®å®šç†ï¼‰", "èåˆå•é¡Œ", "ãã®ä»–"
    ],
    "è‹±èª": [
        "beå‹•è©ãƒ»ä¸€èˆ¬å‹•è©ãƒ»å‘½ä»¤æ–‡", "ä»£åè©ãƒ»ç–‘å•è©ãƒ»ç¾åœ¨é€²è¡Œå½¢", "éå»å½¢ãƒ»éå»é€²è¡Œå½¢ãƒ»æœªæ¥è¡¨ç¾", 
        "åŠ©å‹•è©", "ä¸å®šè©ãƒ»å‹•åè©", "æ¯”è¼ƒ", "å—å‹•æ…‹", "ç¾åœ¨å®Œäº†å½¢", 
        "åˆ†è©ãƒ»åˆ†è©æ§‹æ–‡", "é–¢ä¿‚ä»£åè©", "æ–‡æ§‹é€ ãƒ»æ¥ç¶šè©ï¼ˆSVOO/SVOCãƒ»thatç¯€ï¼‰", 
        "é–“æ¥ç–‘å•æ–‡ãƒ»ä»®å®šæ³•ãƒ»ä»˜åŠ ç–‘å•æ–‡", "èåˆå•é¡Œ", "ãã®ä»–"
    ],
    "ç†ç§‘": [
        "ã€ç‰©ç†ã€‘å…‰ãƒ»éŸ³ãƒ»åŠ›", "ã€ç‰©ç†ã€‘é›»æµã¨ç£ç•Œ", "ã€ç‰©ç†ã€‘é‹å‹•ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼", 
        "ã€åŒ–å­¦ã€‘èº«ã®å›ã‚Šã®ç‰©è³ªãƒ»æ°—ä½“ãƒ»æ°´æº¶æ¶²", "ã€åŒ–å­¦ã€‘åŒ–å­¦å¤‰åŒ–ã¨åŸå­ãƒ»åˆ†å­", 
        "ã€åŒ–å­¦ã€‘åŒ–å­¦å¤‰åŒ–ã¨ã‚¤ã‚ªãƒ³ãƒ»é›»æ± ", "ã€ç”Ÿç‰©ã€‘æ¤ç‰©ã®ç”Ÿæ´»ã¨ç¨®é¡", 
        "ã€ç”Ÿç‰©ã€‘å‹•ç‰©ã®ç”Ÿæ´»ã¨ç”Ÿç‰©ã®å¤‰é·", "ã€ç”Ÿç‰©ã€‘ç”Ÿå‘½ã®é€£ç¶šæ€§ï¼ˆéºä¼ãƒ»ç´°èƒï¼‰", 
        "ã€åœ°å­¦ã€‘å¤§åœ°ã®å¤‰åŒ–ï¼ˆç«å±±ãƒ»åœ°éœ‡ãƒ»åœ°å±¤ï¼‰", "ã€åœ°å­¦ã€‘æ°—è±¡ã¨ãã®å¤‰åŒ–", 
        "ã€åœ°å­¦ã€‘åœ°çƒã¨å®‡å®™", "èåˆå•é¡Œ", "ãã®ä»–"
    ],
    "ç¤¾ä¼š": [
        "ã€åœ°ç†ã€‘ä¸–ç•Œã®å§¿ãƒ»æ°—å€™ãƒ»ç”Ÿæ´»æ–‡åŒ–", "ã€åœ°ç†ã€‘ä¸–ç•Œã®è«¸åœ°åŸŸ", 
        "ã€åœ°ç†ã€‘æ—¥æœ¬ã®å§¿ãƒ»ç”£æ¥­ãƒ»è³‡æºã‚¨ãƒãƒ«ã‚®ãƒ¼", "ã€åœ°ç†ã€‘æ—¥æœ¬ã®è«¸åœ°åŸŸ", 
        "ã€æ­´å²ã€‘å¤ä»£ã€œä¸­ä¸–ï¼ˆæ–‡æ˜ã€œå®¤ç”ºï¼‰", "ã€æ­´å²ã€‘è¿‘ä¸–ï¼ˆå®‰åœŸæ¡ƒå±±ãƒ»æ±Ÿæˆ¸ï¼‰", 
        "ã€æ­´å²ã€‘è¿‘ä»£â‘ ï¼ˆæ˜æ²»ã€œç¬¬ä¸€æ¬¡å¤§æˆ¦ï¼‰", "ã€æ­´å²ã€‘è¿‘ä»£â‘¡ã€œç¾ä»£ï¼ˆæ˜­å’Œã€œç¾åœ¨ï¼‰", 
        "ã€å…¬æ°‘ã€‘ç¾ä»£ç¤¾ä¼šãƒ»æ—¥æœ¬å›½æ†²æ³•ãƒ»äººæ¨©", "ã€å…¬æ°‘ã€‘æ”¿æ²»ã®ä»•çµ„ã¿", 
        "ã€å…¬æ°‘ã€‘çµŒæ¸ˆã®ä»•çµ„ã¿", "ã€å…¬æ°‘ã€‘å›½éš›ç¤¾ä¼šãƒ»ç’°å¢ƒå•é¡Œ", "èåˆå•é¡Œ", "ãã®ä»–"
    ]
}

# ---------------------------------------------------------
# ğŸ› ï¸ é–¢æ•°å®šç¾©
# ---------------------------------------------------------
def ask_gemini_robust(prompt, image_list=None, use_flash=False):
    max_retries = 3
    if image_list:
        target_model = model_vision
    elif use_flash:
        target_model = model_flash
    else:
        target_model = model_pro

    for attempt in range(max_retries):
        try:
            if image_list:
                response = target_model.generate_content([prompt] + image_list)
            else:
                response = target_model.generate_content(prompt)
            return response.text
        except Exception as e:
            if "429" in str(e) or "Quota" in str(e):
                st.toast(f"â³ ã‚¢ã‚¯ã‚»ã‚¹é›†ä¸­...å¾…æ©Ÿä¸­ ({attempt+1}/3)")
                time.sleep((attempt + 1) * 3)
            else:
                return f"ã‚¨ãƒ©ãƒ¼: {e}"
    return "âŒ æ··é›‘ã®ãŸã‚å¿œç­”ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

def detect_subject(file_name):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ•™ç§‘ã‚’åˆ¤å®šã—ã¾ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡æ‘˜ã«ã‚ˆã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆä¾‹ï¼šç¤¾ä¼š_å²©æ‰‹çœŒ.csvï¼‰ã‹ã‚‰ç›´æ¥åˆ¤å®šã—ã¾ã™ã€‚
    """
    name_str = str(file_name)
    
    # æ•™ç§‘ãƒªã‚¹ãƒˆ
    subjects = ['æ•°å­¦', 'è‹±èª', 'ç†ç§‘', 'ç¤¾ä¼š', 'å›½èª']
    
    for sub in subjects:
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«æ•™ç§‘åãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’æ¡ç”¨
        if sub in name_str:
            return sub
            
    return 'ãã®ä»–'

def parse_csv(file):
    try:
        file.seek(0)
        try:
            df = pd.read_csv(file, header=None)
        except:
            file.seek(0)
            df = pd.read_csv(file, header=None, encoding='cp932')
        
        header_row_mask = df.apply(lambda r: r.astype(str).str.contains('å¤§å•|å†…å®¹').any(), axis=1)
        if len(df[header_row_mask]) > 0:
            idx = df[header_row_mask].index[0]
            target_row = df.iloc[idx]
            col_idx = 0
            for c in df.columns:
                val = str(target_row[c])
                if 'å¤§å•' in val or 'å†…å®¹' in val:
                    col_idx = c
                    break
            
            subset = df.iloc[idx:, col_idx:].reset_index(drop=True).T
            subset.columns = [str(val).strip() for val in subset.iloc[0]]
            subset = subset[1:]
            
            if 'å¤§å•' in subset.columns: subset = subset.dropna(subset=['å¤§å•'])
            subset['ç‚¹æ•°'] = pd.to_numeric(subset['ç‚¹æ•°'], errors='coerce').fillna(0)
            subset['é…ç‚¹'] = pd.to_numeric(subset['é…ç‚¹'], errors='coerce').fillna(0)
            subset['ãƒ•ã‚¡ã‚¤ãƒ«å'] = str(file.name)
            
            # ã€ä¿®æ­£ã€‘ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ•™ç§‘ã‚’åˆ¤å®š
            subset['æ•™ç§‘'] = detect_subject(file.name)
            
            if 'ç‚¹æ•°' in subset.columns:
                return subset
    except:
        pass
    return None

def process_and_categorize():
    if not st.session_state['data_store']:
        st.session_state['clean_df'] = pd.DataFrame()
        return

    # å˜å…ƒæ•´ç†ã¯Flashã§é«˜é€ŸåŒ–
    model_label = MODEL_NAME_FLASH
    
    with st.status(f"ğŸš€ ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã¦ã„ã¾ã™... (Engine: {model_label})", expanded=True) as status:
        st.write("ğŸ“‚ 1. ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆä¸­...")
        raw_df = pd.concat(st.session_state['data_store'].values(), ignore_index=True)
        time.sleep(0.2)
        
        st.write("ğŸ” 2. æœªçŸ¥ã®å˜å…ƒã‚’æ¤œç´¢ä¸­...")
        unique_pairs = raw_df[['æ•™ç§‘', 'å†…å®¹']].drop_duplicates()
        unknown_list = []
        
        # æ•™ç§‘ã”ã¨ã®å˜å…ƒåˆ†é¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆç”¨
        tasks = []
        
        for _, row in unique_pairs.iterrows():
            subj = row['æ•™ç§‘']
            topic = str(row['å†…å®¹']).strip()
            
            # æ—¢ã«å®Œå…¨ä¸€è‡´ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚‹ã‹ç¢ºèª
            is_perfect_match = False
            if subj in FIXED_CATEGORIES:
                if topic in FIXED_CATEGORIES[subj]:
                    is_perfect_match = True
            
            if not is_perfect_match and (subj, topic) not in st.session_state['category_map']:
                # ã¾ã ãƒãƒƒãƒ—ã«ãªãã€ãƒªã‚¹ãƒˆã«ã‚‚ãªã„ã‚‚ã®ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
                unknown_list.append(f"{subj}: {topic}")
        
        if unknown_list:
            st.write(f"âš¡ 3. æ–°ã—ã„å˜å…ƒ {len(unknown_list)} ä»¶ã‚’é«˜é€Ÿåˆ†é¡ä¸­...")
            categories_str = json.dumps(FIXED_CATEGORIES, ensure_ascii=False, indent=2)
            
            prompt = f"""
            ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚
            å…¥åŠ›ã•ã‚ŒãŸã€Œæ•™ç§‘: å˜å…ƒåã€ã®ãƒªã‚¹ãƒˆã‚’ã€ä»¥ä¸‹ã®ã€å®šç¾©æ¸ˆã¿ãƒã‚¹ã‚¿ã€‘ã«ã‚ã‚‹ã‚«ãƒ†ã‚´ãƒªåã®ã©ã‚Œã‹ã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚
            
            ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
            1. **å¿…ãš**ã€å®šç¾©æ¸ˆã¿ãƒã‚¹ã‚¿ã€‘ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚«ãƒ†ã‚´ãƒªåã¨**å®Œå…¨ã«ä¸€è‡´ã™ã‚‹æ–‡å­—åˆ—**ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä¸€è¨€ä¸€å¥å¤‰ãˆã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
            2. æ•™ç§‘ã‚‚è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚æ•°å­¦ã®å˜å…ƒã‚’ç¤¾ä¼šã®ã‚«ãƒ†ã‚´ãƒªã«å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚
            3. ã©ã†ã—ã¦ã‚‚å½“ã¦ã¯ã¾ã‚‰ãªã„å ´åˆã¯ã€ãã®æ•™ç§‘å†…ã®ã€Œãã®ä»–ã€ã¾ãŸã¯ã€Œèåˆå•é¡Œã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚
            4. å‡ºåŠ›ã¯JSONå½¢å¼ã®è¾æ›¸ `{{"æ•™ç§‘: å…ƒã®å˜å…ƒå": "å®šç¾©æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªå", ...}}` ã®ã¿ã«ã—ã¦ãã ã•ã„ã€‚

            ã€å®šç¾©æ¸ˆã¿ãƒã‚¹ã‚¿ã€‘
            {categories_str}
            
            ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‘
            """ + "\n".join(unknown_list)
            
            response = ask_gemini_robust(prompt, use_flash=True)
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    mapping = json.loads(json_match.group())
                    for k, v in mapping.items():
                        if ':' in k:
                            s, t = k.split(':', 1)
                            st.session_state['category_map'][(s.strip(), t.strip())] = v.strip()
            except:
                st.warning("âš ï¸ åˆ†é¡ã«ä¸€éƒ¨å¤±æ•—ã—ã¾ã—ãŸãŒç¶šè¡Œã—ã¾ã™")
        else:
            st.write("âœ¨ å…¨ã¦ã®å˜å…ƒã¯åˆ†é¡æ¸ˆã¿ã§ã™")

        st.write("ğŸ’¾ 4. ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ä¸­...")
        df_clean = raw_df.copy()
        if 'è©³ç´°' not in df_clean.columns: df_clean['è©³ç´°'] = df_clean['å†…å®¹']
        
        def apply_mapping(row):
            key = (row['æ•™ç§‘'], str(row['å†…å®¹']).strip())
            mapped_val = st.session_state['category_map'].get(key, row['å†…å®¹'])
            # ãƒãƒƒãƒ”ãƒ³ã‚°ãŒãªã„å ´åˆã¯å…ƒã®å€¤ã‚’ä½¿ã†ãŒã€æœ¬æ¥ã¯ã™ã¹ã¦ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã‚‹ã¯ãš
            return mapped_val if mapped_val else row['å†…å®¹']

        df_clean['å†…å®¹'] = df_clean.apply(apply_mapping, axis=1)
        st.session_state['clean_df'] = df_clean
        
        status.update(label="âœ… è§£æå®Œäº†ï¼", state="complete", expanded=False)

# ---------------------------------------------------------
# ğŸ–¥ï¸ ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# ---------------------------------------------------------
with st.sidebar:
    st.subheader("ğŸ“² ãƒ‡ãƒ¼ã‚¿åŒæœŸ")
    if st.session_state['data_store'] or st.session_state['textbooks']:
        backup_data = {
            'textbooks': st.session_state['textbooks'],
            'data_store': {name: df.to_json(orient='split') for name, df in st.session_state['data_store'].items()}
        }
        json_str = json.dumps(backup_data, ensure_ascii=False)
        st.download_button(
            label="ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜",
            data=json_str,
            file_name=f"juken_backup_{datetime.date.today()}.json",
            mime="application/json"
        )
    
    uploaded_backup = st.file_uploader("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ", type=['json'], key="backup_uploader")
    if uploaded_backup:
        try:
            data = json.load(uploaded_backup)
            if 'textbooks' in data:
                st.session_state['textbooks'] = data['textbooks']
            if 'data_store' in data:
                st.session_state['data_store'] = {}
                for name, df_json in data['data_store'].items():
                    st.session_state['data_store'][name] = pd.read_json(df_json, orient='split')
                st.session_state['clean_df'] = pd.DataFrame()
                st.session_state['category_map'] = {}
                st.success("âœ… å¾©å…ƒæˆåŠŸï¼")
                time.sleep(1)
                st.rerun()
        except Exception as e:
            st.error(f"å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")

    st.markdown("---")
    st.subheader("ğŸ“š å‚è€ƒæ›¸")
    if st.session_state['textbooks']:
        for subj, book in list(st.session_state['textbooks'].items()):
            if book:
                c1, c2 = st.columns([0.8, 0.2])
                c1.write(f"**{subj}**: {book}")
                if c2.button("ğŸ—‘ï¸", key=f"del_book_{subj}"):
                    del st.session_state['textbooks'][subj]
                    st.rerun()
    
    with st.expander("è¿½åŠ ãƒ»ç·¨é›†"):
        with st.form("textbook_form"):
            tb_math = st.text_input("æ•°å­¦", value=st.session_state['textbooks'].get('æ•°å­¦', ''))
            tb_eng = st.text_input("è‹±èª", value=st.session_state['textbooks'].get('è‹±èª', ''))
            tb_sci = st.text_input("ç†ç§‘", value=st.session_state['textbooks'].get('ç†ç§‘', ''))
            tb_soc = st.text_input("ç¤¾ä¼š", value=st.session_state['textbooks'].get('ç¤¾ä¼š', ''))
            tb_jpn = st.text_input("å›½èª", value=st.session_state['textbooks'].get('å›½èª', ''))
            if st.form_submit_button("ä¿å­˜"):
                st.session_state['textbooks'] = {'æ•°å­¦': tb_math, 'è‹±èª': tb_eng, 'ç†ç§‘': tb_sci, 'ç¤¾ä¼š': tb_soc, 'å›½èª': tb_jpn}
                st.rerun()

    st.markdown("---")
    st.subheader("ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«")

    if st.session_state['data_store']:
        for file_name in list(st.session_state['data_store'].keys()):
            c1, c2 = st.columns([0.85, 0.15])
            c1.text(file_name)
            if c2.button("ğŸ—‘ï¸", key=f"del_file_{file_name}"):
                del st.session_state['data_store'][file_name]
                st.session_state['clean_df'] = pd.DataFrame()
                st.rerun()
        
        if st.button("ğŸš¨ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤", type="primary"):
            st.session_state['data_store'] = {}
            st.session_state['clean_df'] = pd.DataFrame()
            st.session_state['category_map'] = {}
            st.rerun()
    else:
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")

# ---------------------------------------------------------
# ğŸ“‚ ãƒ¡ã‚¤ãƒ³ç”»é¢
# ---------------------------------------------------------
st.markdown("### 1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & è§£æ")
col_up, col_btn = st.columns([3, 1])

with col_up:
    uploaded_files = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«", accept_multiple_files=True, type=['csv'], label_visibility="collapsed")

with col_btn:
    if st.button("ğŸš€ AIè§£æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        if uploaded_files:
            new_count = 0
            for file in uploaded_files:
                df = parse_csv(file)
                if df is not None:
                    st.session_state['data_store'][file.name] = df
                    new_count += 1
            if new_count > 0:
                process_and_categorize()
            else:
                st.warning("æœ‰åŠ¹ãªCSVãŒã‚ã‚Šã¾ã›ã‚“")
        elif st.session_state['data_store']:
            process_and_categorize()
        else:
            st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")

if not st.session_state['clean_df'].empty:
    df_show = st.session_state['clean_df']
    st.markdown("---")
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š å…¨ä½“åˆ†æ", "ğŸ“– å¾©ç¿’ï¼†ãƒ†ã‚¹ãƒˆ", "ğŸ“… åˆæ ¼è¨ˆç”»", "ğŸ“· ç”»åƒæ¡ç‚¹"])

    with tab1:
        # å…¨ä½“ãƒ¯ãƒ¼ã‚¹ãƒˆ
        summary = df_show.groupby(['æ•™ç§‘', 'å†…å®¹'])[['ç‚¹æ•°', 'é…ç‚¹']].sum().reset_index()
        summary['å¾—ç‚¹ç‡(%)'] = (summary['ç‚¹æ•°'] / summary['é…ç‚¹'] * 100).round(1)
        summary_clean = pd.DataFrame(summary.to_dict('list'))
        summary_clean.columns = [str(c) for c in summary_clean.columns]

        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader("âš ï¸ å…¨ä½“ï¼šå„ªå…ˆå¾©ç¿’å˜å…ƒ")
            st.dataframe(summary_clean.sort_values('å¾—ç‚¹ç‡(%)').head(10), column_config={"å¾—ç‚¹ç‡(%)": st.column_config.NumberColumn(format="%.1f%%")}, use_container_width=True, hide_index=True)
        with col2:
            st.subheader("æ•™ç§‘åˆ¥å¹³å‡")
            sub_sum = df_show.groupby('æ•™ç§‘')[['ç‚¹æ•°', 'é…ç‚¹']].sum().reset_index()
            sub_sum['å¾—ç‚¹ç‡'] = (sub_sum['ç‚¹æ•°']/sub_sum['é…ç‚¹']*100).round(1)
            sub_sum_clean = pd.DataFrame(sub_sum.to_dict('list'))
            sub_sum_clean.columns = [str(c) for c in sub_sum_clean.columns]
            st.dataframe(sub_sum_clean, hide_index=True)
            
        # æ•™ç§‘ã”ã¨ã®ãƒ¯ãƒ¼ã‚¹ãƒˆè¡¨ç¤º
        st.markdown("---")
        st.subheader("ğŸ“š æ•™ç§‘ã”ã¨ã®å¼±ç‚¹")
        subjects = df_show['æ•™ç§‘'].unique()
        cols = st.columns(len(subjects)) if len(subjects) > 0 else [st.container()]
        
        for i, sub in enumerate(subjects):
            with cols[i]:
                st.markdown(f"**{sub}**")
                sub_df = summary_clean[summary_clean['æ•™ç§‘'] == sub].sort_values('å¾—ç‚¹ç‡(%)').head(5)
                if not sub_df.empty:
                    st.dataframe(
                        sub_df[['å†…å®¹', 'å¾—ç‚¹ç‡(%)']], 
                        column_config={"å¾—ç‚¹ç‡(%)": st.column_config.NumberColumn(format="%.1f%%")},
                        use_container_width=True, 
                        hide_index=True
                    )
                else:
                    st.caption("ãƒ‡ãƒ¼ã‚¿ãªã—")

    with tab2:
        st.subheader("AIå®¶åº­æ•™å¸«ã«ã‚ˆã‚‹æŒ‡å°")
        c1, c2 = st.columns(2)
        with c1: sel_sub = st.selectbox("æ•™ç§‘", summary['æ•™ç§‘'].unique())
        with c2: sel_top = st.selectbox("å˜å…ƒ", summary[summary['æ•™ç§‘']==sel_sub].sort_values('å¾—ç‚¹ç‡(%)')['å†…å®¹'])
        
        target_rows = df_show[(df_show['æ•™ç§‘']==sel_sub) & (df_show['å†…å®¹']==sel_top)]
        rate = (target_rows['ç‚¹æ•°'].sum() / target_rows['é…ç‚¹'].sum() * 100).round(1)
        original_topics = target_rows['è©³ç´°'].unique().tolist()
        original_topics_str = "ã€".join([str(t) for t in original_topics])
        
        st.info(f"å˜å…ƒ: **{sel_top}** (å¾—ç‚¹ç‡: {rate}%)")
        st.caption(f"è©³ç´°: {original_topics_str}")
        
        book = st.session_state['textbooks'].get(sel_sub, "å‚è€ƒæ›¸")
        
        if st.button("â‘  å¾©ç¿’ãƒã‚¤ãƒ³ãƒˆã‚’èã"):
            with st.status(f"ğŸ¤– AI({MODEL_NAME_PRO})ãŒæŒ‡å°å†…å®¹ã‚’ä½œæˆä¸­...", expanded=True) as status:
                st.write("1. æˆç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­...")
                time.sleep(0.5)
                p = f"""
                æ–°æ½Ÿé«˜æ ¡å¿—æœ›ã®ç”Ÿå¾’ã¸ã®æŒ‡å°ã€‚æ•™ç§‘: {sel_sub}, è‹¦æ‰‹ã‚«ãƒ†ã‚´ãƒª: {sel_top}ï¼ˆè©³ç´°: {original_topics_str}ï¼‰, å¾—ç‚¹ç‡: {rate}%, å‚è€ƒæ›¸: {book}ã€‚
                æ–°æ½Ÿé«˜æ ¡åˆæ ¼ãƒ¬ãƒ™ãƒ«ã«å¼•ãä¸Šã’ã‚‹ãŸã‚ã®å¾©ç¿’ãƒã‚¤ãƒ³ãƒˆã€ç†è§£åº¦ãƒã‚§ãƒƒã‚¯é …ç›®3ã¤ã‚’æ•™ãˆã¦ã€‚
                """
                # æŒ‡å°ã¯Pro (use_flash=False)
                res = ask_gemini_robust(p, use_flash=False)
                st.session_state['guide'] = res
                status.update(label="âœ… ã‚¢ãƒ‰ãƒã‚¤ã‚¹ä½œæˆå®Œäº†ï¼", state="complete", expanded=False)
        
        if 'guide' in st.session_state:
            st.markdown(st.session_state['guide'])
            if st.button("â‘¡ ç¢ºèªãƒ†ã‚¹ãƒˆã‚’ä½œæˆ"):
                with st.status("ğŸ“ å…¥è©¦ãƒ¬ãƒ™ãƒ«å•é¡Œã‚’ä½œæˆä¸­...", expanded=True) as status:
                    p2 = f"æ–°æ½Ÿé«˜æ ¡å…¥è©¦ãƒ¬ãƒ™ãƒ«ã€‚{sel_sub}ã®ã€Œ{sel_top}ã€ï¼ˆè©³ç´°: {original_topics_str}ï¼‰ã«é–¢ã™ã‚‹å®Ÿè·µå•é¡Œã‚’1å•ä½œæˆã—ã€è§£ç­”ã¨è§£èª¬ã‚’ä»˜ã‘ã¦ã€‚"
                    # å•é¡Œä½œæˆã¯Pro (use_flash=False)
                    res = ask_gemini_robust(p2, use_flash=False)
                    st.session_state['test'] = res
                    status.update(label="âœ… å•é¡Œä½œæˆå®Œäº†ï¼", state="complete", expanded=False)
        
        if 'test' in st.session_state:
            st.markdown("---")
            st.markdown(st.session_state['test'])

    with tab3:
        if st.button("åˆæ ¼ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ"):
            with st.status("ğŸ“… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç«‹æ¡ˆä¸­...", expanded=True) as status:
                prompt = f"ä»Šæ—¥({datetime.date.today()})ã‹ã‚‰å…¥è©¦({datetime.date(2026, 3, 4)})ã¾ã§ã®æ–°æ½Ÿé«˜æ ¡åˆæ ¼ã«å‘ã‘ãŸå­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                res = ask_gemini_robust(prompt, use_flash=False)
                st.markdown(res)
                status.update(label="âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Œæˆï¼", state="complete", expanded=False)

    with tab4:
        st.subheader("ğŸ“· ç”»åƒæ¡ç‚¹ï¼†æŒ‡å°")
        col_img1, col_img2, col_img3 = st.columns(3)
        with col_img1: img_prob = st.file_uploader("â‘  å•é¡Œç”»åƒ", type=['png', 'jpg', 'jpeg'])
        with col_img2: img_user = st.file_uploader("â‘¡ è§£ç­”ç”»åƒ", type=['png', 'jpg', 'jpeg'])
        with col_img3: img_ans = st.file_uploader("â‘¢ æ¨¡ç¯„è§£ç­”ç”»åƒ", type=['png', 'jpg', 'jpeg'])
        
        if img_prob and img_user and img_ans:
            if st.button(f"ğŸš€ æ¡ç‚¹å®Ÿè¡Œ ({MODEL_NAME_PRO})"):
                with st.status("ğŸ‘€ ç”»åƒã‚’è§£æä¸­...", expanded=True) as status:
                    images = [PIL.Image.open(img_prob), PIL.Image.open(img_user), PIL.Image.open(img_ans)]
                    prompt_v = "æ–°æ½Ÿé«˜æ ¡å¿—æœ›ã€‚3æšã®ç”»åƒï¼ˆå•é¡Œã€ç”Ÿå¾’è§£ç­”ã€æ¨¡ç¯„è§£ç­”ï¼‰ã‹ã‚‰ã€å³å¯†ãªæ¡ç‚¹ã€æ·»å‰Šã€å¼±ç‚¹åˆ†æã€é¡é¡Œã®æç¤ºã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
                    res = ask_gemini_robust(prompt_v, images)
                    st.markdown(res)
                    status.update(label="âœ… æ¡ç‚¹å®Œäº†ï¼", state="complete", expanded=False)
else:
    st.info("ğŸ‘† ä¸Šè¨˜ã‹ã‚‰CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã€ŒAIè§£æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
