import streamlit as st
import pandas as pd
import google.generativeai as genai
import datetime
import PIL.Image
import json
import re
import time

# ==========================================
# ğŸ” åˆæœŸè¨­å®š & ãƒ¢ãƒ‡ãƒ«è‡ªå‹•æ¤œå‡º
# ==========================================
st.set_page_config(page_title="æ–°æ½Ÿé«˜æ ¡ åˆæ ¼ãƒŠãƒ“", layout="wide")
st.title("ğŸ”ï¸ æ–°æ½Ÿé«˜æ ¡ åˆæ ¼ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ & å¾¹åº•å¾©ç¿’")

try:
    api_key = st.secrets["GEMINI_API_KEY"]
except:
    api_key = ""

if not api_key:
    st.warning("âš ï¸ Secretsã«APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

genai.configure(api_key=api_key)

# ---------------------------------------------------------
# ğŸ¤– æœ€å¼·ã®ãƒ¢ãƒ‡ãƒ«è‡ªå‹•æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ (Ver. 3.0å¯¾å¿œ)
# ---------------------------------------------------------
def get_best_pro_model():
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ä¸­ã‹ã‚‰ã€Gemini 3.0ã‚’å«ã‚€æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•ã§æ¢ã™"""
    try:
        all_models = [m.name.replace("models/", "") for m in genai.list_models()]
        
        # å„ªå…ˆé †ä½ãƒªã‚¹ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        priority_list = [
            "gemini-3-pro",           # æœ¬å‘½
            "gemini-3-pro-preview",   # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰ˆ
            "gemini-3.0-pro",         # è¡¨è¨˜æºã‚Œå¯¾å¿œ
            "gemini-2.5-pro",         # 2.5ç³»
            "gemini-2.0-pro-exp",     # 2.0ç³»å®Ÿé¨“ç‰ˆ
            "gemini-1.5-pro-002",     # 1.5ç³»æœ€æ–°
            "gemini-1.5-pro-latest",
            "gemini-1.5-pro",
            "gemini-pro"
        ]
        
        for model_name in priority_list:
            if model_name in all_models:
                return model_name
        
        pro_models = [m for m in all_models if "pro" in m and "vision" not in m]
        if pro_models:
            pro_models.sort(reverse=True)
            return pro_models[0]
                
        return "gemini-1.5-flash"
        
    except Exception as e:
        return "gemini-1.5-pro"

MODEL_NAME = get_best_pro_model()

try:
    model_main = genai.GenerativeModel(MODEL_NAME)
    model_vision = genai.GenerativeModel(MODEL_NAME)
    st.sidebar.success(f"ğŸš€ AI Model: {MODEL_NAME} (Connected)")
except Exception as e:
    st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ã€{MODEL_NAME}ã€ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()


# ---------------------------------------------------------
# ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†
# ---------------------------------------------------------
if 'data_store' not in st.session_state: st.session_state['data_store'] = {}
if 'clean_df' not in st.session_state: st.session_state['clean_df'] = pd.DataFrame()
if 'category_map' not in st.session_state: st.session_state['category_map'] = {}
if 'textbooks' not in st.session_state: st.session_state['textbooks'] = {}

FIXED_CATEGORIES = {
    "å›½èª": ["æ¼¢å­—", "æ–‡æ³•", "è©•è«–", "å¤æ–‡", "ãã®ä»–"],
    "æ•°å­¦": ["æ•°ã¨å¼", "æ–¹ç¨‹å¼ãƒ»ä¸ç­‰å¼", "é–¢æ•°(æ¯”ä¾‹ãƒ»1æ¬¡)", "é–¢æ•°(2æ¬¡ãƒ»ãã®ä»–)", "å¹³é¢å›³å½¢", "ç©ºé–“å›³å½¢", "å›³å½¢ã®è¨¼æ˜", "ç¢ºç‡", "ãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨", "æ•´æ•°ãƒ»è¦å‰‡æ€§", "ä½œå›³", "èåˆå•é¡Œãƒ»ãã®ä»–"],
    "è‹±èª": ["å˜èªãƒ»èªå½™", "æ–‡æ³•(æ™‚åˆ¶ãƒ»å‹•è©)", "æ–‡æ³•(æº–å‹•è©ãƒ»é–¢ä¿‚è©)", "æ–‡æ³•(ãã®ä»–)", "é•·æ–‡èª­è§£(ç‰©èª)", "é•·æ–‡èª­è§£(èª¬æ˜æ–‡)", "è‹±ä½œæ–‡", "ãƒªã‚¹ãƒ‹ãƒ³ã‚°", "ä¼šè©±æ–‡", "èªé †æ•´åº", "é©èªè£œå……", "ãã®ä»–"],
    "ç†ç§‘": ["ç‰©ç†(å…‰ãƒ»éŸ³ãƒ»åŠ›)", "ç‰©ç†(é›»æ°—ãƒ»ç£ç•Œ)", "ç‰©ç†(é‹å‹•ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼)", "åŒ–å­¦(ç‰©è³ªãƒ»æ°—ä½“)", "åŒ–å­¦(å¤‰åŒ–ãƒ»åŸå­)", "åŒ–å­¦(ã‚¤ã‚ªãƒ³ãƒ»é›»æ± )", "ç”Ÿç‰©(æ¤ç‰©)", "ç”Ÿç‰©(å‹•ç‰©ãƒ»äººä½“)", "ç”Ÿç‰©(éºä¼ãƒ»é€²åŒ–)", "åœ°å­¦(ç«å±±ãƒ»åœ°å±¤)", "åœ°å­¦(å¤©æ°—ãƒ»æ°—è±¡)", "åœ°å­¦(å¤©ä½“)"],
    "ç¤¾ä¼š": ["åœ°ç†(ä¸–ç•Œ)", "åœ°ç†(æ—¥æœ¬)", "åœ°ç†(è³‡æ–™èª­å–)", "æ­´å²(å¤ä»£ï½ä¸­ä¸–)", "æ­´å²(è¿‘ä¸–)", "æ­´å²(è¿‘ç¾ä»£)", "å…¬æ°‘(ç¾ä»£ç¤¾ä¼šãƒ»äººæ¨©)", "å…¬æ°‘(æ”¿æ²»)", "å…¬æ°‘(çµŒæ¸ˆ)", "å…¬æ°‘(å›½éš›)", "èåˆå•é¡Œ", "ãã®ä»–"]
}

# ---------------------------------------------------------
# ğŸ› ï¸ é–¢æ•°å®šç¾©
# ---------------------------------------------------------
def ask_gemini_robust(prompt, image_list=None):
    """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãAIå‘¼ã³å‡ºã—"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            if image_list:
                response = model_vision.generate_content([prompt] + image_list)
            else:
                response = model_main.generate_content(prompt)
            return response.text
        except Exception as e:
            if "429" in str(e) or "Quota" in str(e):
                st.toast(f"â³ ã‚¢ã‚¯ã‚»ã‚¹é›†ä¸­...æ•°ç§’å¾…æ©Ÿã—ã¾ã™ ({attempt+1}/3)")
                time.sleep((attempt + 1) * 3)
            else:
                return f"ã‚¨ãƒ©ãƒ¼: {e}"
    return "âŒ æ··é›‘ã®ãŸã‚å¿œç­”ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

def parse_csv(file):
    try:
        file.seek(0)
        try:
            df = pd.read_csv(file, header=None)
        except:
            file.seek(0)
            df = pd.read_csv(file, header=None, encoding='cp932')
        
        header_row_mask = df.apply(lambda r: r.astype(str).str.contains('å¤§å•|å†…å®¹').any(), axis=1)
        if len(df[header_row_mask]) > 0:
            idx = df[header_row_mask].index[0]
            target_row = df.iloc[idx]
            col_idx = 0
            for c in df.columns:
                val = str(target_row[c])
                if 'å¤§å•' in val or 'å†…å®¹' in val:
                    col_idx = c
                    break
            
            subset = df.iloc[idx:, col_idx:].reset_index(drop=True).T
            subset.columns = [str(val).strip() for val in subset.iloc[0]]
            subset = subset[1:]
            
            if 'å¤§å•' in subset.columns: subset = subset.dropna(subset=['å¤§å•'])
            subset['ç‚¹æ•°'] = pd.to_numeric(subset['ç‚¹æ•°'], errors='coerce').fillna(0)
            subset['é…ç‚¹'] = pd.to_numeric(subset['é…ç‚¹'], errors='coerce').fillna(0)
            subset['ãƒ•ã‚¡ã‚¤ãƒ«å'] = str(file.name)
            
            for sub in ['æ•°å­¦','è‹±èª','ç†ç§‘','ç¤¾ä¼š','å›½èª']:
                if sub in file.name:
                    subset['æ•™ç§‘'] = sub
                    break
            else:
                subset['æ•™ç§‘'] = 'ãã®ä»–'
            
            if 'ç‚¹æ•°' in subset.columns:
                return subset
    except:
        pass
    return None

def process_and_categorize():
    """ã€é€²è¡ŒçŠ¶æ³è¡¨ç¤ºä»˜ãã€‘ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
    if not st.session_state['data_store']:
        # ãƒ‡ãƒ¼ã‚¿ãŒç©ºã«ãªã£ãŸå ´åˆï¼ˆå…¨å‰Šé™¤å¾Œãªã©ï¼‰ã¯ãƒªã‚»ãƒƒãƒˆ
        st.session_state['clean_df'] = pd.DataFrame()
        return

    with st.status("ğŸš€ ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã¦ã„ã¾ã™...", expanded=True) as status:
        st.write("ğŸ“‚ 1. ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆä¸­...")
        raw_df = pd.concat(st.session_state['data_store'].values(), ignore_index=True)
        time.sleep(0.3)
        
        st.write("ğŸ” 2. æœªçŸ¥ã®å˜å…ƒã‚’æ¤œç´¢ä¸­...")
        unique_pairs = raw_df[['æ•™ç§‘', 'å†…å®¹']].drop_duplicates()
        unknown_list = []
        for _, row in unique_pairs.iterrows():
            subj = row['æ•™ç§‘']
            topic = str(row['å†…å®¹']).strip()
            if (subj, topic) not in st.session_state['category_map']:
                unknown_list.append(f"{subj}: {topic}")
        
        if unknown_list:
            st.write(f"ğŸ¤– 3. æ–°ã—ã„å˜å…ƒ {len(unknown_list)} ä»¶ã‚’AI({MODEL_NAME})ãŒåˆ†é¡ä¸­...")
            categories_str = json.dumps(FIXED_CATEGORIES, ensure_ascii=False, indent=2)
            prompt = f"""
            å­¦ç¿’å¡¾ã®æ•™å‹™ã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚
            å…¥åŠ›ã•ã‚ŒãŸã€Œæ•™ç§‘: å˜å…ƒåã€ã‚’ã€ä»¥ä¸‹ã®ã€å®šç¾©æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªãƒªã‚¹ãƒˆã€‘ã‹ã‚‰æœ€ã‚‚é©åˆ‡ãªã‚‚ã®ã«åˆ†é¡ã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            ã€å®šç¾©æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªãƒªã‚¹ãƒˆã€‘
            {categories_str}
            ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‘
            """ + "\n".join(unknown_list)
            
            response = ask_gemini_robust(prompt)
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    mapping = json.loads(json_match.group())
                    for k, v in mapping.items():
                        if ':' in k:
                            s, t = k.split(':', 1)
                            st.session_state['category_map'][(s.strip(), t.strip())] = v.strip()
            except:
                st.warning("âš ï¸ åˆ†é¡ã«ä¸€éƒ¨å¤±æ•—ã—ã¾ã—ãŸãŒç¶šè¡Œã—ã¾ã™")
        else:
            st.write("âœ¨ å…¨ã¦ã®å˜å…ƒã¯åˆ†é¡æ¸ˆã¿ã§ã™")

        st.write("ğŸ’¾ 4. ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ä¸­...")
        df_clean = raw_df.copy()
        if 'è©³ç´°' not in df_clean.columns: df_clean['è©³ç´°'] = df_clean['å†…å®¹']
        
        def apply_mapping(row):
            key = (row['æ•™ç§‘'], str(row['å†…å®¹']).strip())
            return st.session_state['category_map'].get(key, row['å†…å®¹'])

        df_clean['å†…å®¹'] = df_clean.apply(apply_mapping, axis=1)
        st.session_state['clean_df'] = df_clean
        
        status.update(label="âœ… è§£æå®Œäº†ï¼", state="complete", expanded=False)

# ---------------------------------------------------------
# ğŸ–¥ï¸ ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š (å€‹åˆ¥å‰Šé™¤æ©Ÿèƒ½ã‚’è¿½åŠ )
# ---------------------------------------------------------
with st.sidebar:
    st.subheader("ğŸ“š å‚è€ƒæ›¸è¨­å®š")
    
    # ç™»éŒ²æ¸ˆã¿å‚è€ƒæ›¸ã®è¡¨ç¤ºã¨å‰Šé™¤
    if st.session_state['textbooks']:
        st.caption("ç™»éŒ²æ¸ˆã¿:")
        for subj, book in list(st.session_state['textbooks'].items()):
            c1, c2 = st.columns([0.8, 0.2])
            c1.write(f"**{subj}**: {book}")
            if c2.button("ğŸ—‘ï¸", key=f"del_book_{subj}"):
                del st.session_state['textbooks'][subj]
                st.rerun()
    
    # æ–°è¦ç™»éŒ²ãƒ•ã‚©ãƒ¼ãƒ 
    with st.expander("æ–°è¦ç™»éŒ²ãƒ»ç·¨é›†"):
        with st.form("textbook_form"):
            tb_math = st.text_input("æ•°å­¦", value=st.session_state['textbooks'].get('æ•°å­¦', ''), placeholder="ä¾‹: ãƒãƒ£ãƒ¼ãƒˆå¼")
            tb_eng = st.text_input("è‹±èª", value=st.session_state['textbooks'].get('è‹±èª', ''), placeholder="ä¾‹: æ•™ç§‘æ›¸")
            tb_sci = st.text_input("ç†ç§‘", value=st.session_state['textbooks'].get('ç†ç§‘', ''), placeholder="ä¾‹: è‡ªç”±è‡ªåœ¨")
            tb_soc = st.text_input("ç¤¾ä¼š", value=st.session_state['textbooks'].get('ç¤¾ä¼š', ''), placeholder="ä¾‹: ç”¨èªé›†")
            tb_jpn = st.text_input("å›½èª", value=st.session_state['textbooks'].get('å›½èª', ''), placeholder="ä¾‹: ä¾¿è¦§")
            if st.form_submit_button("ä¿å­˜"):
                st.session_state['textbooks'] = {'æ•°å­¦': tb_math, 'è‹±èª': tb_eng, 'ç†ç§‘': tb_sci, 'ç¤¾ä¼š': tb_soc, 'å›½èª': tb_jpn}
                st.rerun()

    st.markdown("---")
    st.subheader("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†")

    # ç™»éŒ²æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤ºã¨å‰Šé™¤
    if st.session_state['data_store']:
        st.success(f"{len(st.session_state['data_store'])} ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«")
        with st.expander("ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§", expanded=True):
            for file_name in list(st.session_state['data_store'].keys()):
                c1, c2 = st.columns([0.85, 0.15])
                c1.text(file_name)
                if c2.button("ğŸ—‘ï¸", key=f"del_file_{file_name}"):
                    del st.session_state['data_store'][file_name]
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¶ˆãˆãŸã‚‰å†è§£æãŒå¿…è¦ãªã®ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                    st.session_state['clean_df'] = pd.DataFrame() 
                    st.rerun()
        
        if st.button("å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤", type="primary"):
            st.session_state['data_store'] = {}
            st.session_state['clean_df'] = pd.DataFrame()
            st.session_state['category_map'] = {}
            st.rerun()
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ã¯ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")

# ---------------------------------------------------------
# ğŸ“‚ ãƒ¡ã‚¤ãƒ³ç”»é¢
# ---------------------------------------------------------
st.markdown("### 1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & è§£æ")
col_up, col_btn = st.columns([3, 1])

with col_up:
    uploaded_files = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«", accept_multiple_files=True, type=['csv'], label_visibility="collapsed")

with col_btn:
    if st.button("ğŸš€ AIè§£æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        if uploaded_files:
            new_count = 0
            for file in uploaded_files:
                df = parse_csv(file)
                if df is not None:
                    st.session_state['data_store'][file.name] = df
                    new_count += 1
            if new_count > 0:
                process_and_categorize()
            else:
                st.warning("æœ‰åŠ¹ãªCSVãŒã‚ã‚Šã¾ã›ã‚“")
        elif st.session_state['data_store']:
            process_and_categorize()
        else:
            st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")

if not st.session_state['clean_df'].empty:
    df_show = st.session_state['clean_df']
    st.markdown("---")
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š å…¨ä½“åˆ†æ", "ğŸ“– å¾©ç¿’ï¼†ãƒ†ã‚¹ãƒˆ", "ğŸ“… åˆæ ¼è¨ˆç”»", "ğŸ“· ç”»åƒæ¡ç‚¹"])

    with tab1:
        summary = df_show.groupby(['æ•™ç§‘', 'å†…å®¹'])[['ç‚¹æ•°', 'é…ç‚¹']].sum().reset_index()
        summary['å¾—ç‚¹ç‡(%)'] = (summary['ç‚¹æ•°'] / summary['é…ç‚¹'] * 100).round(1)
        summary_clean = pd.DataFrame(summary.to_dict('list'))
        summary_clean.columns = [str(c) for c in summary_clean.columns]

        col1, col2 = st.columns([2, 1])
        with col1:
            st.subheader("âš ï¸ å„ªå…ˆå¾©ç¿’å˜å…ƒ")
            st.dataframe(summary_clean.sort_values('å¾—ç‚¹ç‡(%)').head(10), column_config={"å¾—ç‚¹ç‡(%)": st.column_config.NumberColumn(format="%.1f%%")}, use_container_width=True, hide_index=True)
        with col2:
            st.subheader("æ•™ç§‘åˆ¥å¹³å‡")
            sub_sum = df_show.groupby('æ•™ç§‘')[['ç‚¹æ•°', 'é…ç‚¹']].sum().reset_index()
            sub_sum['å¾—ç‚¹ç‡'] = (sub_sum['ç‚¹æ•°']/sub_sum['é…ç‚¹']*100).round(1)
            sub_sum_clean = pd.DataFrame(sub_sum.to_dict('list'))
            sub_sum_clean.columns = [str(c) for c in sub_sum_clean.columns]
            st.dataframe(sub_sum_clean, hide_index=True)

    with tab2:
        st.subheader("AIå®¶åº­æ•™å¸«ã«ã‚ˆã‚‹æŒ‡å°")
        c1, c2 = st.columns(2)
        with c1: sel_sub = st.selectbox("æ•™ç§‘", summary['æ•™ç§‘'].unique())
        with c2: sel_top = st.selectbox("å˜å…ƒ", summary[summary['æ•™ç§‘']==sel_sub].sort_values('å¾—ç‚¹ç‡(%)')['å†…å®¹'])
        
        target_rows = df_show[(df_show['æ•™ç§‘']==sel_sub) & (df_show['å†…å®¹']==sel_top)]
        rate = (target_rows['ç‚¹æ•°'].sum() / target_rows['é…ç‚¹'].sum() * 100).round(1)
        original_topics = target_rows['è©³ç´°'].unique().tolist()
        original_topics_str = "ã€".join([str(t) for t in original_topics])
        
        st.info(f"å˜å…ƒ: **{sel_top}** (å¾—ç‚¹ç‡: {rate}%)")
        st.caption(f"è©³ç´°: {original_topics_str}")
        
        book = st.session_state['textbooks'].get(sel_sub, "å‚è€ƒæ›¸")
        
        if st.button("â‘  å¾©ç¿’ãƒã‚¤ãƒ³ãƒˆã‚’èã"):
            with st.status(f"ğŸ¤– AI({MODEL_NAME})ãŒæŒ‡å°å†…å®¹ã‚’ä½œæˆä¸­...", expanded=True) as status:
                st.write("1. æˆç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­...")
                time.sleep(0.5)
                st.write("2. æ–°æ½Ÿé«˜æ ¡ã®å‡ºé¡Œå‚¾å‘ã¨ç…§åˆä¸­...")
                p = f"""
                æ–°æ½Ÿé«˜æ ¡å¿—æœ›ã®ç”Ÿå¾’ã¸ã®æŒ‡å°ã€‚æ•™ç§‘: {sel_sub}, è‹¦æ‰‹ã‚«ãƒ†ã‚´ãƒª: {sel_top}ï¼ˆè©³ç´°: {original_topics_str}ï¼‰, å¾—ç‚¹ç‡: {rate}%, å‚è€ƒæ›¸: {book}ã€‚
                æ–°æ½Ÿé«˜æ ¡åˆæ ¼ãƒ¬ãƒ™ãƒ«ã«å¼•ãä¸Šã’ã‚‹ãŸã‚ã®å¾©ç¿’ãƒã‚¤ãƒ³ãƒˆã€ç†è§£åº¦ãƒã‚§ãƒƒã‚¯é …ç›®3ã¤ã‚’æ•™ãˆã¦ã€‚
                """
                res = ask_gemini_robust(p)
                st.session_state['guide'] = res
                status.update(label="âœ… ã‚¢ãƒ‰ãƒã‚¤ã‚¹ä½œæˆå®Œäº†ï¼", state="complete", expanded=False)
        
        if 'guide' in st.session_state:
            st.markdown(st.session_state['guide'])
            if st.button("â‘¡ ç¢ºèªãƒ†ã‚¹ãƒˆã‚’ä½œæˆ"):
                with st.status("ğŸ“ å…¥è©¦ãƒ¬ãƒ™ãƒ«å•é¡Œã‚’ä½œæˆä¸­...", expanded=True) as status:
                    st.write("1. éå»å•ã®å‚¾å‘ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­...")
                    p2 = f"æ–°æ½Ÿé«˜æ ¡å…¥è©¦ãƒ¬ãƒ™ãƒ«ã€‚{sel_sub}ã®ã€Œ{sel_top}ã€ï¼ˆè©³ç´°: {original_topics_str}ï¼‰ã«é–¢ã™ã‚‹å®Ÿè·µå•é¡Œã‚’1å•ä½œæˆã—ã€è§£ç­”ã¨è§£èª¬ã‚’ä»˜ã‘ã¦ã€‚"
                    res = ask_gemini_robust(p2)
                    st.session_state['test'] = res
                    status.update(label="âœ… å•é¡Œä½œæˆå®Œäº†ï¼", state="complete", expanded=False)
        
        if 'test' in st.session_state:
            st.markdown("---")
            st.markdown(st.session_state['test'])

    with tab3:
        if st.button("åˆæ ¼ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ"):
            with st.status("ğŸ“… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç«‹æ¡ˆä¸­...", expanded=True) as status:
                st.write("1. å…¥è©¦æ—¥ã¾ã§ã®æ—¥æ•°ã‚’è¨ˆç®—ä¸­...")
                st.write("2. å¼±ç‚¹å˜å…ƒã®é…åˆ†ã‚’èª¿æ•´ä¸­...")
                prompt = f"ä»Šæ—¥({datetime.date.today()})ã‹ã‚‰å…¥è©¦({datetime.date(2026, 3, 4)})ã¾ã§ã®æ–°æ½Ÿé«˜æ ¡åˆæ ¼ã«å‘ã‘ãŸå­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                res = ask_gemini_robust(prompt)
                st.markdown(res)
                status.update(label="âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Œæˆï¼", state="complete", expanded=False)

    with tab4:
        st.subheader("ğŸ“· ç”»åƒæ¡ç‚¹ï¼†æŒ‡å°")
        col_img1, col_img2, col_img3 = st.columns(3)
        with col_img1: img_prob = st.file_uploader("â‘  å•é¡Œç”»åƒ", type=['png', 'jpg', 'jpeg'])
        with col_img2: img_user = st.file_uploader("â‘¡ è§£ç­”ç”»åƒ", type=['png', 'jpg', 'jpeg'])
        with col_img3: img_ans = st.file_uploader("â‘¢ æ¨¡ç¯„è§£ç­”ç”»åƒ", type=['png', 'jpg', 'jpeg'])
        
        if img_prob and img_user and img_ans:
            if st.button(f"ğŸš€ æ¡ç‚¹å®Ÿè¡Œ ({MODEL_NAME})"):
                with st.status("ğŸ‘€ ç”»åƒã‚’è§£æä¸­...", expanded=True) as status:
                    st.write("1. ç”»åƒã‹ã‚‰æ–‡å­—ã¨å›³å½¢ã‚’èªè­˜ä¸­...")
                    images = [PIL.Image.open(img_prob), PIL.Image.open(img_user), PIL.Image.open(img_ans)]
                    st.write("2. è§£ç­”ã®è«–ç†ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
                    prompt_v = "æ–°æ½Ÿé«˜æ ¡å¿—æœ›ã€‚3æšã®ç”»åƒï¼ˆå•é¡Œã€ç”Ÿå¾’è§£ç­”ã€æ¨¡ç¯„è§£ç­”ï¼‰ã‹ã‚‰ã€å³å¯†ãªæ¡ç‚¹ã€æ·»å‰Šã€å¼±ç‚¹åˆ†æã€é¡é¡Œã®æç¤ºã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
                    res = ask_gemini_robust(prompt_v, images)
                    st.markdown(res)
                    status.update(label="âœ… æ¡ç‚¹å®Œäº†ï¼", state="complete", expanded=False)
else:
    st.info("ğŸ‘† ä¸Šè¨˜ã‹ã‚‰CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã€ŒAIè§£æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
